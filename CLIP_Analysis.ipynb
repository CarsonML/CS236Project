{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T6nzaedK_Aj"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "QomAr6aJNvxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "model, preprocess = clip.load('ViT-B/32', device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juW_SA3gOVr1",
        "outputId": "839362a8-c4a1-4337-bc3c-5cfcc074e851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 285MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_strings = [['a brunette person', 'a blonde person'],\n",
        "                ['an young person', 'an old person'],\n",
        "                ['brunette', 'blonde'],\n",
        "                ['old', 'young'],\n",
        "                ['weird', 'normal'],\n",
        "                ['orange', 'blue'],\n",
        "                ['light', 'dark'],\n",
        "                ['happy', 'sad']]\n",
        "labels = ['b2b-person', 'y2o-person', 'b2b', 'y2o', 'w2n', 'o2b', 'l2d', 'h2s']\n",
        "n = len(test_strings)"
      ],
      "metadata": {
        "id": "qSQCXNrsQju4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'data/b2b_final'\n",
        "paths = [os.path.join(folder, file) for file in os.listdir(folder)]\n",
        "paths = [path for path in paths if path.endswith('.png')]"
      ],
      "metadata": {
        "id": "XNNmszz8XnIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = len(paths)"
      ],
      "metadata": {
        "id": "0VA-zm4t1AVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyLKiV9A3Ql-",
        "outputId": "563f190e-09e7-40be-d654-16810066c9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_lists = []\n",
        "for path in tqdm.tqdm(paths):\n",
        "  image = preprocess(Image.open(path)).unsqueeze(0).to(device)\n",
        "  results = []\n",
        "\n",
        "  for binary in test_strings:\n",
        "    text = clip.tokenize(binary).to(device)\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image)\n",
        "        text_features = model.encode_text(text)\n",
        "\n",
        "        logits_per_image, logits_per_text = model(image, text)\n",
        "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "        results.append(probs.tolist()[0])\n",
        "  result_lists.append(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdOWzdQsPDDA",
        "outputId": "3edca456-dfc3-488f-ce75-87d1231752de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:09<00:00,  2.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "averages = []\n",
        "for i in range(n):\n",
        "  sum = 0\n",
        "  for j in range(m):\n",
        "    sum += result_lists[j][i][1]\n",
        "  averages.append(sum / m)"
      ],
      "metadata": {
        "id": "E43xgv2y0Fyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao8hd4iI106v",
        "outputId": "f34f39d8-b4bd-418b-91cd-d13d465667be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6023711424607497,\n",
              " 0.1309070587158203,\n",
              " 0.7629327774047852,\n",
              " 0.5301889272836539,\n",
              " 0.5477576622596154,\n",
              " 0.45837637094350964,\n",
              " 0.6165020282451923,\n",
              " 0.4525105403019832]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ra89Ovuc08Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(paths)):\n",
        "  path = paths[i]\n",
        "  with open(path[:-4] + '_CLIP.json', 'w') as f:\n",
        "    json.dump({labels[j]:result_lists[i][j] for j in range(n)}, f, indent=2)"
      ],
      "metadata": {
        "id": "SmszdsOJPO5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}